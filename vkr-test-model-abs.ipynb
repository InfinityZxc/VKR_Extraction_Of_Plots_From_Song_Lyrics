{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8360901,"sourceType":"datasetVersion","datasetId":4811394},{"sourceId":8412071,"sourceType":"datasetVersion","datasetId":4820877},{"sourceId":8442818,"sourceType":"datasetVersion","datasetId":5028467},{"sourceId":8449059,"sourceType":"datasetVersion","datasetId":4979439}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-20T09:58:36.329359Z","iopub.execute_input":"2024-05-20T09:58:36.330042Z","iopub.status.idle":"2024-05-20T09:58:36.353326Z","shell.execute_reply.started":"2024-05-20T09:58:36.329973Z","shell.execute_reply":"2024-05-20T09:58:36.352099Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/song-interpretation-dataset/dataset_test.json\n/kaggle/input/song-interpretation-dataset/dataset_not_negative_256_clean.pkl\n/kaggle/input/song-interpretation-dataset/dataset_full_256_clean.json\n/kaggle/input/song-interpretation-dataset/interpretation_tags.csv\n/kaggle/input/song-interpretation-dataset/dataset_positive_256_clean.json\n/kaggle/input/song-interpretation-dataset/dataset_full_256_clean.pkl\n/kaggle/input/song-interpretation-dataset/interpretation_test_tags.csv\n/kaggle/input/song-interpretation-dataset/dataset_not_negative_256_clean.json\n/kaggle/input/song-interpretation-dataset/dataset_test.pkl\n/kaggle/input/song-interpretation-dataset/dataset_positive_256_clean.pkl\n/kaggle/input/combined-partial/combined_second_tags.csv\n/kaggle/input/combined-partial/combined_train.csv\n/kaggle/input/combined-partial/combined_first_tags.csv\n/kaggle/input/combined-partial/combined_tags.csv\n/kaggle/input/combined-partial/combined_test.csv\n/kaggle/input/combined-partial/combined_validation.csv\n/kaggle/input/tmp-results/generated_sum_coref_train.csv\n/kaggle/input/tmp-results/generated_sum_coref_test.csv\n/kaggle/input/tmp-results/generated_sum_coref_validation.csv\n/kaggle/input/tmp-results/generated_coref_test.csv\n/kaggle/input/tmp-results/generated_coref_validation.csv\n/kaggle/input/tmp-results/generated_coref_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers datasets evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-05-20T09:58:36.355644Z","iopub.execute_input":"2024-05-20T09:58:36.356734Z","iopub.status.idle":"2024-05-20T09:58:51.510471Z","shell.execute_reply.started":"2024-05-20T09:58:36.356693Z","shell.execute_reply":"2024-05-20T09:58:51.509145Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.2)\nRequirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport time\n\nfrom huggingface_hub import notebook_login\n\nfrom sklearn.model_selection import train_test_split\n\nimport re\nfrom nltk.corpus import stopwords\n\nimport torch\n\nimport evaluate\nimport datasets\n\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorForSeq2Seq\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nfrom transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoModelForCausalLM","metadata":{"execution":{"iopub.status.busy":"2024-05-20T09:58:51.513685Z","iopub.execute_input":"2024-05-20T09:58:51.514147Z","iopub.status.idle":"2024-05-20T09:59:13.586026Z","shell.execute_reply.started":"2024-05-20T09:58:51.514095Z","shell.execute_reply":"2024-05-20T09:59:13.584914Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-05-20 09:59:01.496003: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-20 09:59:01.496165: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-20 09:59:01.655222: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_df = pd.read_csv('/kaggle/input/combined-partial/combined_tags.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:08:33.394912Z","iopub.execute_input":"2024-05-20T10:08:33.395333Z","iopub.status.idle":"2024-05-20T10:08:34.214624Z","shell.execute_reply.started":"2024-05-20T10:08:33.395302Z","shell.execute_reply":"2024-05-20T10:08:34.213363Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"combined_df.value_counts('tag')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:17.653416Z","iopub.execute_input":"2024-05-18T00:54:17.653889Z","iopub.status.idle":"2024-05-18T00:54:17.676125Z","shell.execute_reply.started":"2024-05-18T00:54:17.653855Z","shell.execute_reply":"2024-05-18T00:54:17.675212Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"tag\npop        15673\nrock       10153\ncountry     3847\nrap         3350\nrb          2206\nmisc          52\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#train, test = train_test_split(combined_df, test_size=0.2)\n#validation, test = train_test_split(test, test_size=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:17.677075Z","iopub.execute_input":"2024-05-18T00:54:17.677345Z","iopub.status.idle":"2024-05-18T00:54:17.682678Z","shell.execute_reply.started":"2024-05-18T00:54:17.677322Z","shell.execute_reply":"2024-05-18T00:54:17.681845Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/combined-partial/combined_train.csv')\nvalidation_df = pd.read_csv('/kaggle/input/combined-partial/combined_validation.csv')\ntest_df = pd.read_csv('/kaggle/input/combined-partial/combined_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:17.684062Z","iopub.execute_input":"2024-05-18T00:54:17.684437Z","iopub.status.idle":"2024-05-18T00:54:18.962793Z","shell.execute_reply.started":"2024-05-18T00:54:17.684406Z","shell.execute_reply":"2024-05-18T00:54:18.961767Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n                           \"you're\": \"you are\", \"you've\": \"you have\"}","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:02:06.769284Z","iopub.execute_input":"2024-05-20T10:02:06.769945Z","iopub.status.idle":"2024-05-20T10:02:06.784949Z","shell.execute_reply.started":"2024-05-20T10:02:06.769888Z","shell.execute_reply":"2024-05-20T10:02:06.783980Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"stop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:18.980004Z","iopub.execute_input":"2024-05-18T00:54:18.980338Z","iopub.status.idle":"2024-05-18T00:54:18.995668Z","shell.execute_reply.started":"2024-05-18T00:54:18.980302Z","shell.execute_reply":"2024-05-18T00:54:18.994867Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    text = text.lower() # lowercase\n    text = text.split() # convert have'nt -> have not\n    for i in range(len(text)):\n        word = text[i]\n        if word in contraction_mapping:\n            text[i] = contraction_mapping[word]\n    text = \" \".join(text)\n    '''\n    text = text.split()\n    newtext = []\n    for word in text:\n        if word not in stop_words:\n            newtext.append(word)\n    text = \" \".join(newtext)\n    '''\n    text = text.replace(\"'s\",'') # convert your's -> your\n    #text = re.sub(r'\\(.*\\)','',text) # remove (words)\n    text = re.sub(r'[[].*?[]]','',text) # remove [words]\n    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n    text = re.sub(r'\\.',' . ',text)\n    return text\n\ndef preprocess_summary(text):\n    text = text.lower() # lowercase\n    text = text.split() # convert have'nt -> have not\n    for i in range(len(text)):\n        word = text[i]\n        if word in contraction_mapping:\n            text[i] = contraction_mapping[word]\n    text = \" \".join(text)\n    '''\n    text = text.split()\n    newtext = []\n    for word in text:\n        if word not in stop_words:\n            newtext.append(word)\n    text = \" \".join(newtext)\n    '''\n    text = text.replace(\"'s\",'') # convert your's -> your\n    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n    text = re.sub(r'\\.',' . ',text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-05-20T10:01:34.231296Z","iopub.execute_input":"2024-05-20T10:01:34.231691Z","iopub.status.idle":"2024-05-20T10:01:34.245202Z","shell.execute_reply.started":"2024-05-20T10:01:34.231661Z","shell.execute_reply":"2024-05-20T10:01:34.243970Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_df['clean_text'] = train_df['unredacted_text'].apply(lambda x:preprocess_text(x))\ntrain_df['clean_summary'] = train_df['unredacted_summary'].apply(lambda x:preprocess_summary(x))\n\nvalidation_df['clean_text'] = validation_df['unredacted_text'].apply(lambda x:preprocess_text(x))\nvalidation_df['clean_summary'] = validation_df['unredacted_summary'].apply(lambda x:preprocess_summary(x))\n\ntest_df['clean_text'] = test_df['unredacted_text'].apply(lambda x:preprocess_text(x))\ntest_df['clean_summary'] = test_df['unredacted_summary'].apply(lambda x:preprocess_summary(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:19.009046Z","iopub.execute_input":"2024-05-18T00:54:19.009293Z","iopub.status.idle":"2024-05-18T00:54:24.094670Z","shell.execute_reply.started":"2024-05-18T00:54:19.009270Z","shell.execute_reply":"2024-05-18T00:54:24.093732Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1559666327.py:19: FutureWarning: Possible nested set at position 1\n  text = re.sub(r'[[].*?[]]','',text) # remove [words]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df = pd.read_csv('/kaggle/input/song-interpretation-dataset/interpretation_tags.csv')\n#test_df = pd.read_csv('/kaggle/input/song-interpretation-dataset/interpretation_test_tags.csv')\n\n#train_df, validation_df = train_test_split(train_df, test_size = 0.1, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:24.095925Z","iopub.execute_input":"2024-05-18T00:54:24.096229Z","iopub.status.idle":"2024-05-18T00:54:24.100265Z","shell.execute_reply.started":"2024-05-18T00:54:24.096203Z","shell.execute_reply":"2024-05-18T00:54:24.099353Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tmp-results/generated_sum_coref_train.csv')\nvalidation_df = pd.read_csv('/kaggle/input/tmp-results/generated_sum_coref_validation.csv')\ntest_df = pd.read_csv('/kaggle/input/tmp-results/generated_sum_coref_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:24.101376Z","iopub.execute_input":"2024-05-18T00:54:24.102213Z","iopub.status.idle":"2024-05-18T00:54:27.504586Z","shell.execute_reply.started":"2024-05-18T00:54:24.102178Z","shell.execute_reply":"2024-05-18T00:54:27.503647Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = datasets.Dataset.from_dict(train_df)\nvalidation_dataset = datasets.Dataset.from_dict(validation_df)\ntest_dataset = datasets.Dataset.from_dict(test_df)\n\ndataset_dict = datasets.DatasetDict({\"train\":train_dataset, \"test\":test_dataset, \"validation\":validation_dataset})","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:27.505883Z","iopub.execute_input":"2024-05-18T00:54:27.506269Z","iopub.status.idle":"2024-05-18T00:54:29.029036Z","shell.execute_reply.started":"2024-05-18T00:54:27.506234Z","shell.execute_reply":"2024-05-18T00:54:29.028231Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"dataset_dict","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:29.030083Z","iopub.execute_input":"2024-05-18T00:54:29.030376Z","iopub.status.idle":"2024-05-18T00:54:29.035873Z","shell.execute_reply.started":"2024-05-18T00:54:29.030350Z","shell.execute_reply":"2024-05-18T00:54:29.035022Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['title', 'tag', 'unredacted_text', 'clean_text', 'id', 'artist', 'unredacted_summary', 'clean_summary', 'generated_summary', 'coref_text', 'coref_summary', 'coref_generated_summary'],\n        num_rows: 26110\n    })\n    test: Dataset({\n        features: ['title', 'tag', 'unredacted_text', 'clean_text', 'id', 'artist', 'unredacted_summary', 'clean_summary', 'generated_summary', 'coref_text', 'coref_summary', 'coref_generated_summary'],\n        num_rows: 3235\n    })\n    validation: Dataset({\n        features: ['title', 'tag', 'unredacted_text', 'clean_text', 'id', 'artist', 'unredacted_summary', 'clean_summary', 'generated_summary', 'coref_text', 'coref_summary', 'coref_generated_summary'],\n        num_rows: 3267\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"notebook_login()\n# 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","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:56:08.863274Z","iopub.execute_input":"2024-05-18T00:56:08.863650Z","iopub.status.idle":"2024-05-18T00:56:08.884770Z","shell.execute_reply.started":"2024-05-18T00:56:08.863619Z","shell.execute_reply":"2024-05-18T00:56:08.883915Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cec99f10d46e4df6b79297803c35e455"}},"metadata":{}}]},{"cell_type":"code","source":"checkpoint = \"google-t5/t5-small\"\n# checkpoint = \"google-t5/t5-base\"\n# checkpoint = \"google-t5/t5-large\"\n# checkpoint = \"openai-community/gpt2-xl\"\n# checkpoint = \"google/pegasus-large\"\n# checkpoint = \"facebook/bart-base\"\n\nmodel_name = 'test_sum_abs_t5_small_wasa_coref_stops'","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:29.073022Z","iopub.execute_input":"2024-05-18T00:54:29.073290Z","iopub.status.idle":"2024-05-18T00:54:29.077709Z","shell.execute_reply.started":"2024-05-18T00:54:29.073267Z","shell.execute_reply":"2024-05-18T00:54:29.076864Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"if checkpoint == \"facebook/bart-base\":\n    tokenizer = BartTokenizer.from_pretrained(checkpoint)\nelse:\n    tokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:29.078800Z","iopub.execute_input":"2024-05-18T00:54:29.079094Z","iopub.status.idle":"2024-05-18T00:54:31.116731Z","shell.execute_reply.started":"2024-05-18T00:54:29.079071Z","shell.execute_reply":"2024-05-18T00:54:31.115910Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43d27b27b2ad461494fad1007f7855ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1782a1ef53d48ccac103c999be15a7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20ae47520d9d4dcaa7ab7f8d455d1a64"}},"metadata":{}}]},{"cell_type":"code","source":"prefix = ''\nsuffix = ''\nif checkpoint == \"google-t5/t5-small\" or checkpoint == \"google-t5/t5-large\" or checkpoint == \"google-t5/t5-base\":\n    prefix = \"summarize: \"\nelif checkpoint == \"openai-community/gpt2-xl\":\n    suffix = \" TL;DR\"\n\n\ndef preprocess_function(dataset):\n    #inputs = [prefix + doc + suffix for doc in dataset[\"clean_text\"]]\n    inputs = [prefix + doc + suffix for doc in dataset[\"coref_text\"]]\n    \n    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n\n    #labels = tokenizer(text_target=dataset[\"clean_summary\"], max_length=128, truncation=True)\n    labels = tokenizer(text_target=dataset[\"coref_summary\"], max_length=128, truncation=True)\n    \n    #labels = tokenizer(text_target=dataset[\"clean_summary\"], max_length=256, truncation=True)\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:31.118056Z","iopub.execute_input":"2024-05-18T00:54:31.118497Z","iopub.status.idle":"2024-05-18T00:54:31.125404Z","shell.execute_reply.started":"2024-05-18T00:54:31.118462Z","shell.execute_reply":"2024-05-18T00:54:31.124438Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenized_summary = dataset_dict.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:54:31.126770Z","iopub.execute_input":"2024-05-18T00:54:31.127091Z","iopub.status.idle":"2024-05-18T00:54:59.743459Z","shell.execute_reply.started":"2024-05-18T00:54:31.127065Z","shell.execute_reply":"2024-05-18T00:54:59.742335Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/26110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11e60fad3f804d11b4965506cea8d7be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3235 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b024e4b6fdc4418ac56e8736f99c2d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3267 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f29163397894c2d9190b529e907bf1e"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:55:33.406013Z","iopub.execute_input":"2024-05-18T00:55:33.406744Z","iopub.status.idle":"2024-05-18T00:55:33.410966Z","shell.execute_reply.started":"2024-05-18T00:55:33.406701Z","shell.execute_reply":"2024-05-18T00:55:33.409926Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:55:34.725779Z","iopub.execute_input":"2024-05-18T00:55:34.726979Z","iopub.status.idle":"2024-05-18T00:55:35.324488Z","shell.execute_reply.started":"2024-05-18T00:55:34.726939Z","shell.execute_reply":"2024-05-18T00:55:35.323761Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n\n    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    result[\"gen_len\"] = np.mean(prediction_lens)\n\n    return {k: round(v, 4) for k, v in result.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:55:36.676367Z","iopub.execute_input":"2024-05-18T00:55:36.676752Z","iopub.status.idle":"2024-05-18T00:55:36.686409Z","shell.execute_reply.started":"2024-05-18T00:55:36.676696Z","shell.execute_reply":"2024-05-18T00:55:36.685222Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"if checkpoint == \"google-t5/t5-small\" or checkpoint == \"google-t5/t5-base\" or checkpoint == \"google-t5/t5-large\" or checkpoint == \"google/pegasus-large\":\n    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\nelif checkpoint == \"openai-community/gpt2-xl\":\n    model = AutoModelForCausalLM.from_pretrained(checkpoint)\nelif checkpoint == \"facebook/bart-base\":\n    model = BartForConditionalGeneration.from_pretrained(checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:55:38.381597Z","iopub.execute_input":"2024-05-18T00:55:38.382480Z","iopub.status.idle":"2024-05-18T00:55:40.221364Z","shell.execute_reply.started":"2024-05-18T00:55:38.382440Z","shell.execute_reply":"2024-05-18T00:55:40.220454Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8f2430fb8f4963a8f2b456a855e7f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde23f0e8cef431ba87efbd63ee441c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8fa0fbd28c345efb9d04b37f13c2a28"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=model_name,\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=4,\n    predict_with_generate=True,\n    fp16=True,\n    push_to_hub=True,\n    #generation_max_length = 128,\n    load_best_model_at_end = True,\n    metric_for_best_model = 'rouge1',\n    save_strategy = \"epoch\",\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_summary[\"train\"],\n    eval_dataset=tokenized_summary[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\n# fa999572c1bb81c13893a4ccf225bb1c8bf30bc4","metadata":{"execution":{"iopub.status.busy":"2024-05-18T00:56:19.500596Z","iopub.execute_input":"2024-05-18T00:56:19.501425Z","iopub.status.idle":"2024-05-18T02:33:56.623347Z","shell.execute_reply.started":"2024-05-18T00:56:19.501387Z","shell.execute_reply":"2024-05-18T02:33:56.622175Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240518_005629-j47e1n8z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/infinity_foundation/huggingface/runs/j47e1n8z' target=\"_blank\">super-wood-19</a></strong> to <a href='https://wandb.ai/infinity_foundation/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/infinity_foundation/huggingface' target=\"_blank\">https://wandb.ai/infinity_foundation/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/infinity_foundation/huggingface/runs/j47e1n8z' target=\"_blank\">https://wandb.ai/infinity_foundation/huggingface/runs/j47e1n8z</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6528' max='6528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6528/6528 1:36:56, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.382400</td>\n      <td>0.319957</td>\n      <td>0.361300</td>\n      <td>0.265800</td>\n      <td>0.335400</td>\n      <td>0.335400</td>\n      <td>18.998800</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.354700</td>\n      <td>0.308104</td>\n      <td>0.366500</td>\n      <td>0.271200</td>\n      <td>0.339900</td>\n      <td>0.339800</td>\n      <td>18.999100</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.343100</td>\n      <td>0.301614</td>\n      <td>0.368200</td>\n      <td>0.273300</td>\n      <td>0.341800</td>\n      <td>0.341400</td>\n      <td>19.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.332100</td>\n      <td>0.300398</td>\n      <td>0.367000</td>\n      <td>0.272300</td>\n      <td>0.340900</td>\n      <td>0.340700</td>\n      <td>19.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nThere were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6528, training_loss=0.3663179707877776, metrics={'train_runtime': 5844.6592, 'train_samples_per_second': 17.869, 'train_steps_per_second': 1.117, 'total_flos': 2.6806488182882304e+16, 'train_loss': 0.3663179707877776, 'epoch': 4.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T02:33:56.624993Z","iopub.execute_input":"2024-05-18T02:33:56.625281Z","iopub.status.idle":"2024-05-18T02:33:59.252353Z","shell.execute_reply.started":"2024-05-18T02:33:56.625256Z","shell.execute_reply":"2024-05-18T02:33:59.251229Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/InfinityC/test_sum_abs_t5_small_wasa_coref_stops/commit/7ffaad7925d31b1557721622fd010091e181bcc0', commit_message='End of training', commit_description='', oid='7ffaad7925d31b1557721622fd010091e181bcc0', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}