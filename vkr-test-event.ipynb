{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8442818,"sourceType":"datasetVersion","datasetId":5028467},{"sourceId":8449059,"sourceType":"datasetVersion","datasetId":4979439}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-18T15:41:16.666041Z","iopub.execute_input":"2024-05-18T15:41:16.666758Z","iopub.status.idle":"2024-05-18T15:41:17.558695Z","shell.execute_reply.started":"2024-05-18T15:41:16.666724Z","shell.execute_reply":"2024-05-18T15:41:17.557612Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/generated-results/generated_LexRank_sumy.csv\n/kaggle/input/generated-results/generated_all_bert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_spacy_topicrank.csv\n/kaggle/input/generated-results/generated_spacy_textrank.csv\n/kaggle/input/generated-results/generated_coref_sbert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_all_Lsa_sumy.csv\n/kaggle/input/generated-results/generated_coref_spacy_textrank.csv\n/kaggle/input/generated-results/generated_coref_spacy_topicrank.csv\n/kaggle/input/generated-results/generated_all_sbert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_bert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_all_spacy_textrank.csv\n/kaggle/input/generated-results/generated_all_LexRank_sumy.csv\n/kaggle/input/generated-results/generated_coref_seq_to_seq_bart-base.csv\n/kaggle/input/generated-results/generated_coref_KLSummarizer_sumy.csv\n/kaggle/input/generated-results/generated_coref_Lsa_sumy.csv\n/kaggle/input/generated-results/generated_all_seq_to_seq_bart-base.csv\n/kaggle/input/generated-results/generated_all_spacy_positionrank.csv\n/kaggle/input/generated-results/generated_all_KLSummarizer_sumy.csv\n/kaggle/input/generated-results/generated_coref_spacy_positionrank.csv\n/kaggle/input/generated-results/generated_coref_bert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_Lsa_sumy.csv\n/kaggle/input/generated-results/generated_TextRank_sumy.csv\n/kaggle/input/generated-results/generated_coref_TextRank_sumy.csv\n/kaggle/input/generated-results/generated_seq_to_seq_t5_small.csv\n/kaggle/input/generated-results/generated_all_spacy_topicrank.csv\n/kaggle/input/generated-results/generated_all_seq_to_seq_t5_small.csv\n/kaggle/input/generated-results/generated_coref_LexRank_sumy.csv\n/kaggle/input/generated-results/generated_coref.csv\n/kaggle/input/generated-results/generated_all_Luhn_sumy.csv\n/kaggle/input/generated-results/generated_all_TextRank_sumy.csv\n/kaggle/input/generated-results/generated_seq_to_seq_bart-base.csv\n/kaggle/input/generated-results/generated_spacy_positionrank.csv\n/kaggle/input/generated-results/generated_KLSummarizer_sumy.csv\n/kaggle/input/generated-results/generated_coref_Luhn_sumy.csv\n/kaggle/input/generated-results/generated_sbert_ext_sum_simple.csv\n/kaggle/input/generated-results/generated_Luhn_sumy.csv\n/kaggle/input/generated-results/generated_coref_seq_to_seq_t5_small.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install sumy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('/kaggle/input/tmp-results/generated_coref_validation.csv', sep=',')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T15:47:58.558717Z","iopub.execute_input":"2024-05-18T15:47:58.559839Z","iopub.status.idle":"2024-05-18T15:47:59.010397Z","shell.execute_reply.started":"2024-05-18T15:47:58.559800Z","shell.execute_reply":"2024-05-18T15:47:59.009348Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sample = val_df.sample()\nsample['clean_text'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T15:56:02.931468Z","iopub.execute_input":"2024-05-18T15:56:02.932394Z","iopub.status.idle":"2024-05-18T15:56:02.939030Z","shell.execute_reply.started":"2024-05-18T15:56:02.932364Z","shell.execute_reply":"2024-05-18T15:56:02.937992Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\" . remember how you used to say . you could not wait 'til tomorrow for a brand new day? . and no fuss when you had to ride the bus . you would just add a little blush to paralyze your school crush . now you are older and the weight is on your shoulder . makes the world a little colder, no more hidin' in the old days . be strong, do not you give up hope . it will get hard, life like a jump rope . up, down, up, down . up, down, up, down, yeah . because it will get hard . remember, life like a jump rope . up, down, up, down . up, down, up, down, yeah . it will get hard . because it will get hard . there'll be a bump and there will be a bruise . there'll be alarms and there will be a snooze . there'll be a path that you will have to choose . there'll be a win and there will be a lose . and you gotta to hold your head up high and . watch all the negative go by . do not ever be ashamed to cry, you go ahead . because life like a jump rope . up, down, up, down . up, down, up, down, yeah . it will get hard . remember, life like a jump rope . up, down, up, down . up, down, up, down, yeah . it will get hard, c'mon . i want to tell you that everything will be okay . that everything will eventually turn itself to gold . so keep pushing through it all . do not follow, lead the way . do not lose yourself or your hope . because life like a jump rope . (up, down, up, down . up, down, up, down, yeah) . you stomp your feet so hard you make it pound . raise it back up to the top, and now we are never coming down . up, down, stomp your feet, spin around . clap hands to the rhythm then you slip down . stomp your feet so hard you make it pound . raise it back up to the top, and now we are never coming down . up, down, up, down . up, down, up, down, yeah . it will get hard . remember, life like a jump rope . up, down, up, down . up, down, up, down, yeah . it will get hard . because it will get hard . (up, down, up, down . up, down, up, down, yeah) . life like a jump rope . up, down, up, down . up, down, up, down, yeah . woah, because life like a jump rope\""},"metadata":{}}]},{"cell_type":"code","source":"sample['clean_summary'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:12:18.987159Z","iopub.execute_input":"2024-05-18T16:12:18.987595Z","iopub.status.idle":"2024-05-18T16:12:18.998000Z","shell.execute_reply.started":"2024-05-18T16:12:18.987559Z","shell.execute_reply":"2024-05-18T16:12:18.996668Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'because it will get hard .  remember lifes like a jump rope .  come on .  i want to tell you that everything will be okay'"},"metadata":{}}]},{"cell_type":"code","source":"text = sample['clean_text'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:08:47.932019Z","iopub.execute_input":"2024-05-18T16:08:47.932416Z","iopub.status.idle":"2024-05-18T16:08:47.938739Z","shell.execute_reply.started":"2024-05-18T16:08:47.932388Z","shell.execute_reply":"2024-05-18T16:08:47.937434Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sumy.parsers.plaintext import PlaintextParser\nfrom sumy.nlp.tokenizers import Tokenizer\nfrom sumy.summarizers.luhn import LuhnSummarizer","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:11:22.730884Z","iopub.execute_input":"2024-05-18T16:11:22.731290Z","iopub.status.idle":"2024-05-18T16:11:22.738415Z","shell.execute_reply.started":"2024-05-18T16:11:22.731261Z","shell.execute_reply":"2024-05-18T16:11:22.737172Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sent_count = 4","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:11:36.422662Z","iopub.execute_input":"2024-05-18T16:11:36.423393Z","iopub.status.idle":"2024-05-18T16:11:36.427777Z","shell.execute_reply.started":"2024-05-18T16:11:36.423359Z","shell.execute_reply":"2024-05-18T16:11:36.426746Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"parser = PlaintextParser.from_string(text,Tokenizer(\"english\"))\nsummarizer_luhn = LuhnSummarizer()\nsentences = summarizer_luhn(parser.document, sent_count)\nresult = ' '\nfor sent in sentences:\n    result += (sent._text + ' ')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:16:15.578067Z","iopub.execute_input":"2024-05-18T16:16:15.578458Z","iopub.status.idle":"2024-05-18T16:16:15.595865Z","shell.execute_reply.started":"2024-05-18T16:16:15.578429Z","shell.execute_reply":"2024-05-18T16:16:15.594939Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for sentence in summarizer_luhn(parser.document, sent_count):\n    print(sentence)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:17:00.166282Z","iopub.execute_input":"2024-05-18T16:17:00.166673Z","iopub.status.idle":"2024-05-18T16:17:00.173932Z","shell.execute_reply.started":"2024-05-18T16:17:00.166641Z","shell.execute_reply":"2024-05-18T16:17:00.172871Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"it will get hard, life like a jump rope .\nyou stomp your feet so hard you make it pound .\nraise it back up to the top, and now we are never coming down .\nraise it back up to the top, and now we are never coming down .\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division, print_function, unicode_literals\n\n\nfrom collections import namedtuple\nfrom operator import attrgetter\nfrom sumy.utils import ItemsCount\nfrom sumy._compat import to_unicode\nfrom sumy.nlp.stemmers import null_stemmer\n\n\nSentenceInfo = namedtuple(\"SentenceInfo\", (\"sentence\", \"order\", \"rating\",))\n\n\nclass AbstractSummarizer(object):\n    def __init__(self, stemmer=null_stemmer):\n        if not callable(stemmer):\n            raise ValueError(\"Stemmer has to be a callable object\")\n\n        self._stemmer = stemmer\n\n    def __call__(self, document, sentences_count):\n        raise NotImplementedError(\"This method should be overriden in subclass\")\n\n    def stem_word(self, word):\n        return self._stemmer(self.normalize_word(word))\n\n    @staticmethod\n    def normalize_word(word):\n        return to_unicode(word).lower()\n\n    @staticmethod\n    def _get_best_sentences(sentences, count, rating, *args, **kwargs):\n        rate = rating\n        if isinstance(rating, dict):\n            assert not args and not kwargs\n            def rate(s): return rating[s]\n\n        infos = (SentenceInfo(s, o, rate(s, *args, **kwargs))\n            for o, s in enumerate(sentences))\n\n        # sort sentences by rating in descending order\n        infos = sorted(infos, key=attrgetter(\"rating\"), reverse=True)\n        \n        print(infos[0])\n        \n        # get `count` first best rated sentences\n        if not callable(count):\n            count = ItemsCount(count)\n        infos = count(infos)\n        # sort sentences by their order in document\n        infos = sorted(infos, key=attrgetter(\"order\"))\n\n        return tuple(i.sentence for i in infos)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:00:21.464995Z","iopub.execute_input":"2024-05-18T17:00:21.465890Z","iopub.status.idle":"2024-05-18T17:00:21.477369Z","shell.execute_reply.started":"2024-05-18T17:00:21.465856Z","shell.execute_reply":"2024-05-18T17:00:21.476247Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division, print_function, unicode_literals\n\nfrom sumy.models import TfDocumentModel\n# from sumy.summarizers._summarizer import AbstractSummarizer\n\nclass LuhnSummarizer(AbstractSummarizer):\n    max_gap_size = 4\n    # TODO: better recognition of significant words (automatic)\n    significant_percentage = 1\n    _stop_words = frozenset()\n\n    @property\n    def stop_words(self):\n        return self._stop_words\n\n    @stop_words.setter\n    def stop_words(self, words):\n        self._stop_words = frozenset(map(self.normalize_word, words))\n\n    def __call__(self, document, sentences_count):\n        words = self._get_significant_words(document.words)\n        return self._get_best_sentences(document.sentences,\n            sentences_count, self.rate_sentence, words)\n\n    def _get_significant_words(self, words):\n        words = map(self.normalize_word, words)\n        words = tuple(self.stem_word(w) for w in words if w not in self._stop_words)\n\n        model = TfDocumentModel(words)\n\n        # take only best `significant_percentage` % words\n        best_words_count = int(len(words) * self.significant_percentage)\n        words = model.most_frequent_terms(best_words_count)\n\n        # take only words contained multiple times in document\n        return tuple(t for t in words if model.term_frequency(t) > 1)\n\n    def rate_sentence(self, sentence, significant_stems):\n        ratings = self._get_chunk_ratings(sentence, significant_stems)\n        return max(ratings) if ratings else 0\n\n    def _get_chunk_ratings(self, sentence, significant_stems):\n        chunks = []\n        NONSIGNIFICANT_CHUNK = [0]*self.max_gap_size\n\n        in_chunk = False\n        for order, word in enumerate(sentence.words):\n            stem = self.stem_word(word)\n            # new chunk\n            if stem in significant_stems and not in_chunk:\n                in_chunk = True\n                chunks.append([1])\n            # append word to chunk\n            elif in_chunk:\n                is_significant_word = int(stem in significant_stems)\n                chunks[-1].append(is_significant_word)\n\n            # end of chunk\n            if chunks and chunks[-1][-self.max_gap_size:] == NONSIGNIFICANT_CHUNK:\n                in_chunk = False\n\n        return tuple(map(self._get_chunk_rating, chunks))\n\n    def _get_chunk_rating(self, chunk):\n        chunk = self.__remove_trailing_zeros(chunk)\n        words_count = len(chunk)\n        assert words_count > 0\n\n        significant_words = sum(chunk)\n        if significant_words == 1:\n            return 0\n        else:\n            return significant_words**2 / words_count\n\n    def __remove_trailing_zeros(self, collection):\n        \"\"\"Removes trailing zeroes from indexable collection of numbers\"\"\"\n        index = len(collection) - 1\n        while index >= 0 and collection[index] == 0:\n            index -= 1\n\n        return collection[:index + 1]","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:00:23.846070Z","iopub.execute_input":"2024-05-18T17:00:23.846984Z","iopub.status.idle":"2024-05-18T17:00:23.861758Z","shell.execute_reply.started":"2024-05-18T17:00:23.846950Z","shell.execute_reply":"2024-05-18T17:00:23.860570Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"parser = PlaintextParser.from_string(text,Tokenizer(\"english\"))\nsummarizer_luhn = LuhnSummarizer()\nsentences = summarizer_luhn(parser.document, sent_count)\nresult = ' '\nfor sent in sentences:\n    result += (sent._text + ' ')\nresult","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:00:50.199208Z","iopub.execute_input":"2024-05-18T17:00:50.200425Z","iopub.status.idle":"2024-05-18T17:00:50.221892Z","shell.execute_reply.started":"2024-05-18T17:00:50.200378Z","shell.execute_reply":"2024-05-18T17:00:50.220668Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"SentenceInfo(sentence=<Sentence: raise it back up to the top, and now we are never coming down .>, order=42, rating=14.0)\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"' it will get hard, life like a jump rope . you stomp your feet so hard you make it pound . raise it back up to the top, and now we are never coming down . raise it back up to the top, and now we are never coming down . '"},"metadata":{}}]},{"cell_type":"code","source":"result","metadata":{"execution":{"iopub.status.busy":"2024-05-18T16:16:18.463970Z","iopub.execute_input":"2024-05-18T16:16:18.464725Z","iopub.status.idle":"2024-05-18T16:16:18.471732Z","shell.execute_reply.started":"2024-05-18T16:16:18.464688Z","shell.execute_reply":"2024-05-18T16:16:18.470598Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"' it will get hard, life like a jump rope . you stomp your feet so hard you make it pound . raise it back up to the top, and now we are never coming down . raise it back up to the top, and now we are never coming down . '"},"metadata":{}}]},{"cell_type":"code","source":"import spacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ntext = sample['clean_text'].iloc[0]\n\ndoc = nlp(text)\n    \nfor token in doc:\n    if token.pos_ == 'VERB':\n        print(token.text, token.pos_)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T17:15:10.337671Z","iopub.execute_input":"2024-05-18T17:15:10.338651Z","iopub.status.idle":"2024-05-18T17:15:11.283699Z","shell.execute_reply.started":"2024-05-18T17:15:10.338615Z","shell.execute_reply":"2024-05-18T17:15:11.282629Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"remember VERB\nused VERB\nsay VERB\nwait VERB\nhad VERB\nride VERB\nadd VERB\nparalyze VERB\nmakes VERB\ngive VERB\nget VERB\nget VERB\nremember VERB\nget VERB\nget VERB\nchoose VERB\ngot VERB\nhold VERB\nwatch VERB\ngo VERB\ncry VERB\ngo VERB\nget VERB\nremember VERB\nget VERB\nc'm VERB\nwant VERB\ntell VERB\nturn VERB\nkeep VERB\npushing VERB\nfollow VERB\nlead VERB\nlose VERB\nstomp VERB\nmake VERB\npound VERB\nraise VERB\ncoming VERB\nspin VERB\nclap VERB\nslip VERB\nmake VERB\npound VERB\nraise VERB\ncoming VERB\nget VERB\nremember VERB\nget VERB\nget VERB\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summarizer_luhn = LuhnSummarizer()\n\ndef generate_summary(text):\n    parser = PlaintextParser.from_string(text,Tokenizer(\"english\"))\n    sentences = summarizer_luhn(parser.document, sent_count)\n    result = ' '\n    for sent in sentences:\n        result += (sent._text + ' ')\n    result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = pd.read_csv('/kaggle/input/tmp-results/generated_coref_validation.csv', sep=',')\n\ntemp_df = val_df.sample(10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\ntemp_df['generated_summary'] = temp_df['clean_text'].apply(lambda x:generate_summary(x))\ntemp_df['coref_generated_summary'] = temp_df['coref_text'].apply(lambda x:generate_summary(x))\n\nend = time.time()\nprint('time: ', end - start)","metadata":{},"execution_count":null,"outputs":[]}]}